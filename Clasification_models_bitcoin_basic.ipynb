{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from datetime import datetime\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "import numbers\n",
    "from sklearn import model_selection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aquí, a futuro, habría que añadir los datos del Nasdaq, oro y/o Ethereum para ver los resultados\n",
    "data_for_use = pd.read_csv('./bitcoin_data_for_use_v4.csv', index_col=0)\n",
    "data_gold = pd.read_csv('./gold_data_for_use.csv', index_col=0)\n",
    "data_nasdaq = pd.read_csv('./nasdaq_data_for_use.csv', index_col=0)\n",
    "\n",
    "data_for_use_w_gold = data_for_use.merge(data_gold, left_index=True, right_index=True)\n",
    "data_for_use_w_nasdaq = data_for_use.merge(data_nasdaq, left_index=True, right_index=True)\n",
    "\n",
    "data_for_use_w_all = data_for_use_w_gold.merge(data_nasdaq, left_index=True, right_index=True)\n",
    "\n",
    "data_for_use_basic = data_for_use.drop(labels=['dia',\n",
    "                    'varV0','varV1','varV2','varV3','varV4','varV5','varV6','varV7','varV8','varV9',\n",
    "                    'varV10','varV11','varV12','varV13','varV14','varV15','varV16','varV17','varV18','varV19',\n",
    "                    'varV20','varV21','varV22','varV23','varV24','varV25','varV26','varV27','varV28','varV29', 'outlier'\n",
    "                    ], axis=1)\n",
    "\n",
    "data_for_use_bone_deep = data_for_use_basic.drop(labels=['varPm93',\n",
    "                    'varPm123','varPm153','varPm183','varPm213','varPm243','varPm273','varPm303','varPm333',\n",
    "                    'varPs30','varPs37','varPs44','varPs51','varPs58','varPs65','varPs72','varPs79','varPs86'\n",
    "                    ], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>varP0</th>\n",
       "      <th>varP1</th>\n",
       "      <th>varP2</th>\n",
       "      <th>varP3</th>\n",
       "      <th>varP4</th>\n",
       "      <th>varP5</th>\n",
       "      <th>varP6</th>\n",
       "      <th>varP7</th>\n",
       "      <th>varP8</th>\n",
       "      <th>varP9</th>\n",
       "      <th>...</th>\n",
       "      <th>varPm123</th>\n",
       "      <th>varPm153</th>\n",
       "      <th>varPm183</th>\n",
       "      <th>varPm213</th>\n",
       "      <th>varPm243</th>\n",
       "      <th>varPm273</th>\n",
       "      <th>varPm303</th>\n",
       "      <th>varPm333</th>\n",
       "      <th>subida</th>\n",
       "      <th>varPSig</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2016-01-01</th>\n",
       "      <td>0.008749</td>\n",
       "      <td>0.009252</td>\n",
       "      <td>-0.014696</td>\n",
       "      <td>0.025348</td>\n",
       "      <td>-0.001287</td>\n",
       "      <td>0.013298</td>\n",
       "      <td>-0.084229</td>\n",
       "      <td>0.001468</td>\n",
       "      <td>0.028445</td>\n",
       "      <td>0.013352</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.183043</td>\n",
       "      <td>0.102536</td>\n",
       "      <td>0.131128</td>\n",
       "      <td>-0.060556</td>\n",
       "      <td>-0.054907</td>\n",
       "      <td>-0.068731</td>\n",
       "      <td>0.146342</td>\n",
       "      <td>-0.152457</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.002063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-02</th>\n",
       "      <td>-0.002063</td>\n",
       "      <td>0.008749</td>\n",
       "      <td>0.009252</td>\n",
       "      <td>-0.014696</td>\n",
       "      <td>0.025348</td>\n",
       "      <td>-0.001287</td>\n",
       "      <td>0.013298</td>\n",
       "      <td>-0.084229</td>\n",
       "      <td>0.001468</td>\n",
       "      <td>0.028445</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.192818</td>\n",
       "      <td>0.102514</td>\n",
       "      <td>0.134863</td>\n",
       "      <td>-0.054992</td>\n",
       "      <td>-0.057860</td>\n",
       "      <td>-0.081400</td>\n",
       "      <td>0.215208</td>\n",
       "      <td>-0.139772</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.007907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-03</th>\n",
       "      <td>-0.007907</td>\n",
       "      <td>-0.002063</td>\n",
       "      <td>0.008749</td>\n",
       "      <td>0.009252</td>\n",
       "      <td>-0.014696</td>\n",
       "      <td>0.025348</td>\n",
       "      <td>-0.001287</td>\n",
       "      <td>0.013298</td>\n",
       "      <td>-0.084229</td>\n",
       "      <td>0.001468</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.184701</td>\n",
       "      <td>0.077969</td>\n",
       "      <td>0.162987</td>\n",
       "      <td>-0.049962</td>\n",
       "      <td>-0.093926</td>\n",
       "      <td>-0.044459</td>\n",
       "      <td>0.202201</td>\n",
       "      <td>-0.173499</td>\n",
       "      <td>True</td>\n",
       "      <td>0.007163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-04</th>\n",
       "      <td>0.007163</td>\n",
       "      <td>-0.007907</td>\n",
       "      <td>-0.002063</td>\n",
       "      <td>0.008749</td>\n",
       "      <td>0.009252</td>\n",
       "      <td>-0.014696</td>\n",
       "      <td>0.025348</td>\n",
       "      <td>-0.001287</td>\n",
       "      <td>0.013298</td>\n",
       "      <td>-0.084229</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.203476</td>\n",
       "      <td>0.048931</td>\n",
       "      <td>0.208760</td>\n",
       "      <td>-0.021020</td>\n",
       "      <td>-0.100629</td>\n",
       "      <td>-0.075179</td>\n",
       "      <td>0.272441</td>\n",
       "      <td>-0.241372</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.002611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-05</th>\n",
       "      <td>-0.002611</td>\n",
       "      <td>0.007163</td>\n",
       "      <td>-0.007907</td>\n",
       "      <td>-0.002063</td>\n",
       "      <td>0.008749</td>\n",
       "      <td>0.009252</td>\n",
       "      <td>-0.014696</td>\n",
       "      <td>0.025348</td>\n",
       "      <td>-0.001287</td>\n",
       "      <td>0.013298</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.182999</td>\n",
       "      <td>0.047772</td>\n",
       "      <td>0.192408</td>\n",
       "      <td>-0.049361</td>\n",
       "      <td>-0.062588</td>\n",
       "      <td>-0.077178</td>\n",
       "      <td>0.234350</td>\n",
       "      <td>-0.244859</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.006609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-09-21</th>\n",
       "      <td>-0.050185</td>\n",
       "      <td>-0.093449</td>\n",
       "      <td>-0.021089</td>\n",
       "      <td>0.021386</td>\n",
       "      <td>-0.010795</td>\n",
       "      <td>-0.008157</td>\n",
       "      <td>0.023015</td>\n",
       "      <td>0.047359</td>\n",
       "      <td>-0.023884</td>\n",
       "      <td>0.019066</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.307969</td>\n",
       "      <td>-0.011426</td>\n",
       "      <td>-0.027993</td>\n",
       "      <td>0.819894</td>\n",
       "      <td>0.296122</td>\n",
       "      <td>0.294667</td>\n",
       "      <td>0.420558</td>\n",
       "      <td>0.264591</td>\n",
       "      <td>True</td>\n",
       "      <td>0.070793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-09-22</th>\n",
       "      <td>0.070793</td>\n",
       "      <td>-0.050185</td>\n",
       "      <td>-0.093449</td>\n",
       "      <td>-0.021089</td>\n",
       "      <td>0.021386</td>\n",
       "      <td>-0.010795</td>\n",
       "      <td>-0.008157</td>\n",
       "      <td>0.023015</td>\n",
       "      <td>0.047359</td>\n",
       "      <td>-0.023884</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.274826</td>\n",
       "      <td>-0.054379</td>\n",
       "      <td>-0.048679</td>\n",
       "      <td>0.743330</td>\n",
       "      <td>0.420131</td>\n",
       "      <td>0.265584</td>\n",
       "      <td>0.400979</td>\n",
       "      <td>0.219860</td>\n",
       "      <td>True</td>\n",
       "      <td>0.030306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-09-23</th>\n",
       "      <td>0.030306</td>\n",
       "      <td>0.070793</td>\n",
       "      <td>-0.050185</td>\n",
       "      <td>-0.093449</td>\n",
       "      <td>-0.021089</td>\n",
       "      <td>0.021386</td>\n",
       "      <td>-0.010795</td>\n",
       "      <td>-0.008157</td>\n",
       "      <td>0.023015</td>\n",
       "      <td>0.047359</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.319474</td>\n",
       "      <td>-0.031845</td>\n",
       "      <td>-0.026437</td>\n",
       "      <td>0.690406</td>\n",
       "      <td>0.351016</td>\n",
       "      <td>0.242234</td>\n",
       "      <td>0.466289</td>\n",
       "      <td>0.217606</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.045781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-09-24</th>\n",
       "      <td>-0.045781</td>\n",
       "      <td>0.030306</td>\n",
       "      <td>0.070793</td>\n",
       "      <td>-0.050185</td>\n",
       "      <td>-0.093449</td>\n",
       "      <td>-0.021089</td>\n",
       "      <td>0.021386</td>\n",
       "      <td>-0.010795</td>\n",
       "      <td>-0.008157</td>\n",
       "      <td>0.023015</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.226667</td>\n",
       "      <td>-0.031976</td>\n",
       "      <td>0.058981</td>\n",
       "      <td>0.512089</td>\n",
       "      <td>0.309128</td>\n",
       "      <td>0.316711</td>\n",
       "      <td>0.432640</td>\n",
       "      <td>0.215800</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.002875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-09-25</th>\n",
       "      <td>-0.002875</td>\n",
       "      <td>-0.045781</td>\n",
       "      <td>0.030306</td>\n",
       "      <td>0.070793</td>\n",
       "      <td>-0.050185</td>\n",
       "      <td>-0.093449</td>\n",
       "      <td>-0.021089</td>\n",
       "      <td>0.021386</td>\n",
       "      <td>-0.010795</td>\n",
       "      <td>-0.008157</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.216349</td>\n",
       "      <td>-0.111232</td>\n",
       "      <td>0.109284</td>\n",
       "      <td>0.535708</td>\n",
       "      <td>0.224282</td>\n",
       "      <td>0.541462</td>\n",
       "      <td>0.256068</td>\n",
       "      <td>0.267280</td>\n",
       "      <td>True</td>\n",
       "      <td>0.011516</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2095 rows × 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               varP0     varP1     varP2     varP3     varP4     varP5  \\\n",
       "2016-01-01  0.008749  0.009252 -0.014696  0.025348 -0.001287  0.013298   \n",
       "2016-01-02 -0.002063  0.008749  0.009252 -0.014696  0.025348 -0.001287   \n",
       "2016-01-03 -0.007907 -0.002063  0.008749  0.009252 -0.014696  0.025348   \n",
       "2016-01-04  0.007163 -0.007907 -0.002063  0.008749  0.009252 -0.014696   \n",
       "2016-01-05 -0.002611  0.007163 -0.007907 -0.002063  0.008749  0.009252   \n",
       "...              ...       ...       ...       ...       ...       ...   \n",
       "2021-09-21 -0.050185 -0.093449 -0.021089  0.021386 -0.010795 -0.008157   \n",
       "2021-09-22  0.070793 -0.050185 -0.093449 -0.021089  0.021386 -0.010795   \n",
       "2021-09-23  0.030306  0.070793 -0.050185 -0.093449 -0.021089  0.021386   \n",
       "2021-09-24 -0.045781  0.030306  0.070793 -0.050185 -0.093449 -0.021089   \n",
       "2021-09-25 -0.002875 -0.045781  0.030306  0.070793 -0.050185 -0.093449   \n",
       "\n",
       "               varP6     varP7     varP8     varP9  ...  varPm123  varPm153  \\\n",
       "2016-01-01 -0.084229  0.001468  0.028445  0.013352  ... -0.183043  0.102536   \n",
       "2016-01-02  0.013298 -0.084229  0.001468  0.028445  ... -0.192818  0.102514   \n",
       "2016-01-03 -0.001287  0.013298 -0.084229  0.001468  ... -0.184701  0.077969   \n",
       "2016-01-04  0.025348 -0.001287  0.013298 -0.084229  ... -0.203476  0.048931   \n",
       "2016-01-05 -0.014696  0.025348 -0.001287  0.013298  ... -0.182999  0.047772   \n",
       "...              ...       ...       ...       ...  ...       ...       ...   \n",
       "2021-09-21  0.023015  0.047359 -0.023884  0.019066  ... -0.307969 -0.011426   \n",
       "2021-09-22 -0.008157  0.023015  0.047359 -0.023884  ... -0.274826 -0.054379   \n",
       "2021-09-23 -0.010795 -0.008157  0.023015  0.047359  ... -0.319474 -0.031845   \n",
       "2021-09-24  0.021386 -0.010795 -0.008157  0.023015  ... -0.226667 -0.031976   \n",
       "2021-09-25 -0.021089  0.021386 -0.010795 -0.008157  ... -0.216349 -0.111232   \n",
       "\n",
       "            varPm183  varPm213  varPm243  varPm273  varPm303  varPm333  \\\n",
       "2016-01-01  0.131128 -0.060556 -0.054907 -0.068731  0.146342 -0.152457   \n",
       "2016-01-02  0.134863 -0.054992 -0.057860 -0.081400  0.215208 -0.139772   \n",
       "2016-01-03  0.162987 -0.049962 -0.093926 -0.044459  0.202201 -0.173499   \n",
       "2016-01-04  0.208760 -0.021020 -0.100629 -0.075179  0.272441 -0.241372   \n",
       "2016-01-05  0.192408 -0.049361 -0.062588 -0.077178  0.234350 -0.244859   \n",
       "...              ...       ...       ...       ...       ...       ...   \n",
       "2021-09-21 -0.027993  0.819894  0.296122  0.294667  0.420558  0.264591   \n",
       "2021-09-22 -0.048679  0.743330  0.420131  0.265584  0.400979  0.219860   \n",
       "2021-09-23 -0.026437  0.690406  0.351016  0.242234  0.466289  0.217606   \n",
       "2021-09-24  0.058981  0.512089  0.309128  0.316711  0.432640  0.215800   \n",
       "2021-09-25  0.109284  0.535708  0.224282  0.541462  0.256068  0.267280   \n",
       "\n",
       "            subida   varPSig  \n",
       "2016-01-01   False -0.002063  \n",
       "2016-01-02   False -0.007907  \n",
       "2016-01-03    True  0.007163  \n",
       "2016-01-04   False -0.002611  \n",
       "2016-01-05   False -0.006609  \n",
       "...            ...       ...  \n",
       "2021-09-21    True  0.070793  \n",
       "2021-09-22    True  0.030306  \n",
       "2021-09-23   False -0.045781  \n",
       "2021-09-24   False -0.002875  \n",
       "2021-09-25    True  0.011516  \n",
       "\n",
       "[2095 rows x 50 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_for_use_basic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#aqui se marca lo que se va a usar de verdad para el resto del programa\n",
    "data_for_use = data_for_use_basic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Partimos los datos en train y test por fechas, sin que sea aleatorio, que es como funcionaría\n",
    "# en la realidad el modelo\n",
    "data_no_test, data_test = train_test_split(data_for_use, shuffle=False, test_size=0.2)\n",
    "\n",
    "# Partimos los datos de train nuevamente en validation y train\n",
    "data_train, data_valid = train_test_split(data_no_test, shuffle=False, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separamos la variable que queremos predecir\n",
    "X_train=data_train.drop(labels=['subida', 'varPSig'], axis=1)\n",
    "y_train=data_train['subida']\n",
    "real_train=data_train['varPSig']\n",
    "\n",
    "X_valid=data_valid.drop(labels=['subida', 'varPSig'], axis=1)\n",
    "y_valid=data_valid['subida']\n",
    "real_valid=data_valid['varPSig']\n",
    "\n",
    "X_test=data_test.drop(labels=['subida', 'varPSig'], axis=1)\n",
    "y_test=data_test['subida']\n",
    "real_test=data_test['varPSig']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2016-01-01   -0.002063\n",
       "2016-01-02   -0.007907\n",
       "2016-01-03    0.007163\n",
       "2016-01-04   -0.002611\n",
       "2016-01-05   -0.006609\n",
       "                ...   \n",
       "2019-08-28   -0.025037\n",
       "2019-08-29    0.009250\n",
       "2019-08-30    0.003385\n",
       "2019-08-31    0.013219\n",
       "2019-09-01    0.060339\n",
       "Name: varPSig, Length: 1340, dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "real_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2019-09-02    0.026750\n",
       "2019-09-03   -0.002734\n",
       "2019-09-04   -0.001790\n",
       "2019-09-05   -0.021014\n",
       "2019-09-06    0.015836\n",
       "                ...   \n",
       "2020-07-29    0.000968\n",
       "2020-07-30    0.019103\n",
       "2020-07-31    0.038515\n",
       "2020-08-01   -0.060034\n",
       "2020-08-02    0.017436\n",
       "Name: varPSig, Length: 336, dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "real_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2020-08-03   -0.003597\n",
       "2020-08-04    0.048290\n",
       "2020-08-05    0.002788\n",
       "2020-08-06   -0.015136\n",
       "2020-08-07    0.013151\n",
       "                ...   \n",
       "2021-09-21    0.070793\n",
       "2021-09-22    0.030306\n",
       "2021-09-23   -0.045781\n",
       "2021-09-24   -0.002875\n",
       "2021-09-25    0.011516\n",
       "Name: varPSig, Length: 419, dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "real_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5686567164179105"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Miramos cuántos días sube el bitcoin sobre el total en cada uno de los segmentos\n",
    "# esto nos servirá para hacernos una idea de cómo de buenos son los resultados de los modelos\n",
    "y_train.sum()/y_train.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4851190476190476"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_valid.sum()/y_valid.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5513126491646778"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.sum()/y_test.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tenemos que hacer one-hot encoding sobre la columna \"dia\"\n",
    "#Sobre el resto aplicamos el standardscaler\n",
    "\n",
    "number_columns = X_train.select_dtypes('number').columns\n",
    "\n",
    "t=[\n",
    "    #('dia', \n",
    "    #OneHotEncoder(handle_unknown='ignore'),\n",
    "    #['dia']),\n",
    "    ('scaler', StandardScaler(),number_columns)\n",
    "    ]\n",
    "\n",
    "ct = ColumnTransformer(transformers=t, remainder='passthrough')\n",
    "\n",
    "#data_for_use_t=ct.fit_transform(data_for_use)\n",
    "\n",
    "#X_train=ct.fit_transform(X_train)\n",
    "#X_valid=ct.transform(X_valid)\n",
    "#X_test=ct.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def walk_forward_validation (model, X_train_wfv, y_train_wfv, X_test_wfv, y_test_wfv, real_test_wfv):\n",
    "    y_pred_wfv = list()\n",
    "    #variable que indica si, siguiendo el modelo, estaríamos invertidos o no\n",
    "    dentro=True\n",
    "    resultado_naive=1\n",
    "    resultado_mod=1\n",
    "    resultado_mod_comis=1\n",
    "    for i in range(len(y_test_wfv)):\n",
    "        X_train_wfv_ct=ct.fit_transform(X_train_wfv)\n",
    "        model.fit(X_train_wfv_ct, y_train_wfv)\n",
    "        X_test_wfv_ct=ct.transform(X_test_wfv)\n",
    "        y_pred_next = model.predict(X_test_wfv_ct[i:i+1])\n",
    "        y_pred_wfv.append(y_pred_next[0])\n",
    "        X_train_wfv=X_train_wfv.append(X_test_wfv[i:i+1])\n",
    "        y_train_wfv=y_train_wfv.append(pd.Series(y_test_wfv[i]))\n",
    "        \n",
    "        #suponemos una comisión por compra/venta del 0,15%\n",
    "        if y_pred_next[0]!=dentro:\n",
    "            resultado_mod_comis=resultado_mod_comis*(1-0.0015)\n",
    "        dentro=y_pred_next[0]\n",
    "        \n",
    "        #el naive seimpre se mantiene comprado (o siempre supone que sube)\n",
    "        resultado_naive=resultado_naive*(1+real_test_wfv[i])\n",
    "        #si estamos comprados entonces se nos aplica la subida o bajada del día siguiente\n",
    "        if dentro:\n",
    "            resultado_mod=resultado_mod*(1+real_test_wfv[i])\n",
    "            resultado_mod_comis=resultado_mod_comis*(1+real_test_wfv[i])\n",
    "    \n",
    "    return metrics.confusion_matrix(y_test_wfv, y_pred_wfv), metrics.f1_score(y_test_wfv,y_pred_wfv), \\\n",
    "        metrics.accuracy_score(y_test_wfv,y_pred_wfv), resultado_naive, resultado_mod, resultado_mod_comis\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(penalty='l2', solver='lbfgs', random_state=0)\n",
    "\n",
    "X_train_c=X_train.copy()\n",
    "y_train_c=y_train.copy()\n",
    "X_valid_c=X_valid.copy()\n",
    "y_valid_c=y_valid.copy()\n",
    "\n",
    "\n",
    "conf_mat, f1sc, accsc, resultado_naive, resultado_mod, resultado_mod_comis = \\\n",
    "    walk_forward_validation(lr, X_train_c, y_train_c, X_valid_c, y_valid_c, real_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 31 142]\n",
      " [ 29 134]] 0.6104783599088838 0.49107142857142855\n",
      "1.0869439154370777 0.7815546528988364 0.6889650101117196\n"
     ]
    }
   ],
   "source": [
    "print(conf_mat, f1sc, accsc)\n",
    "print(resultado_naive, resultado_mod, resultado_mod_comis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numero de vecinos aplicado: 1\n",
      "[[ 69 104]\n",
      " [ 60 103]] 0.5567567567567567 0.5119047619047619\n",
      "1.0869439154370777 1.7979590351156092 1.4247232760742718\n",
      "Numero de vecinos aplicado: 2\n",
      "[[105  68]\n",
      " [ 99  64]] 0.4338983050847458 0.5029761904761905\n",
      "1.0869439154370777 0.9897242754924797 0.7819177788720538\n",
      "Numero de vecinos aplicado: 3\n",
      "[[ 56 117]\n",
      " [ 53 110]] 0.5641025641025641 0.49404761904761907\n",
      "1.0869439154370777 1.2469811739041308 0.9925820481082959\n",
      "Numero de vecinos aplicado: 4\n",
      "[[87 86]\n",
      " [76 87]] 0.517857142857143 0.5178571428571429\n",
      "1.0869439154370777 1.417949758675036 1.0920056490084769\n",
      "Numero de vecinos aplicado: 5\n",
      "[[ 45 128]\n",
      " [ 38 125]] 0.6009615384615384 0.5059523809523809\n",
      "1.0869439154370777 0.8733933633009724 0.7207136474747645\n",
      "Numero de vecinos aplicado: 6\n",
      "[[ 69 104]\n",
      " [ 63 100]] 0.544959128065395 0.5029761904761905\n",
      "1.0869439154370777 1.4443239378431028 1.1393562626729876\n",
      "Numero de vecinos aplicado: 7\n",
      "[[ 34 139]\n",
      " [ 33 130]] 0.601851851851852 0.4880952380952381\n",
      "1.0869439154370777 1.1974185579018233 1.0243424768554386\n",
      "Numero de vecinos aplicado: 8\n",
      "[[ 55 118]\n",
      " [ 45 118]] 0.5914786967418546 0.5148809523809523\n",
      "1.0869439154370777 1.6473752223939422 1.359394123174655\n",
      "Numero de vecinos aplicado: 9\n",
      "[[ 30 143]\n",
      " [ 28 135]] 0.6122448979591837 0.49107142857142855\n",
      "1.0869439154370777 1.348148586657468 1.1955928173077581\n",
      "Numero de vecinos aplicado: 10\n",
      "[[ 44 129]\n",
      " [ 42 121]] 0.5859564164648909 0.49107142857142855\n",
      "1.0869439154370777 1.2861520446768417 1.083857537195925\n",
      "Numero de vecinos aplicado: 11\n",
      "[[ 26 147]\n",
      " [ 23 140]] 0.6222222222222222 0.49404761904761907\n",
      "1.0869439154370777 1.4172827553203378 1.2835981147189417\n",
      "Numero de vecinos aplicado: 12\n",
      "[[ 38 135]\n",
      " [ 34 129]] 0.6042154566744731 0.49702380952380953\n",
      "1.0869439154370777 1.1983280385229549 1.040624931277753\n",
      "Numero de vecinos aplicado: 13\n",
      "[[ 19 154]\n",
      " [ 19 144]] 0.6247288503253796 0.4851190476190476\n",
      "1.0869439154370777 0.6980606452945289 0.637936287680368\n",
      "Numero de vecinos aplicado: 14\n",
      "[[ 31 142]\n",
      " [ 26 137]] 0.6199095022624435 0.5\n",
      "1.0869439154370777 1.303683199616404 1.152693233590574\n",
      "Numero de vecinos aplicado: 15\n",
      "[[ 15 158]\n",
      " [ 16 147]] 0.6282051282051283 0.48214285714285715\n",
      "1.0869439154370777 0.693625044548584 0.641540922750745\n",
      "Numero de vecinos aplicado: 16\n",
      "[[ 23 150]\n",
      " [ 23 140]] 0.6181015452538632 0.4851190476190476\n",
      "1.0869439154370777 1.0493376155349365 0.944669917570591\n",
      "Numero de vecinos aplicado: 17\n",
      "[[ 16 157]\n",
      " [ 14 149]] 0.6353944562899786 0.49107142857142855\n",
      "1.0869439154370777 1.1167653205835026 1.0453866850395914\n",
      "Numero de vecinos aplicado: 18\n",
      "[[ 20 153]\n",
      " [ 21 142]] 0.6200873362445415 0.48214285714285715\n",
      "1.0869439154370777 0.9864781968006648 0.9042229068082043\n",
      "Numero de vecinos aplicado: 19\n",
      "[[ 14 159]\n",
      " [ 10 153]] 0.6442105263157895 0.49702380952380953\n",
      "1.0869439154370777 1.3527606068653673 1.277754966637371\n",
      "Numero de vecinos aplicado: 20\n",
      "[[ 18 155]\n",
      " [ 15 148]] 0.6351931330472103 0.49404761904761907\n",
      "1.0869439154370777 1.3663860186734895 1.2599959427845646\n",
      "Numero de vecinos aplicado: 21\n",
      "[[ 13 160]\n",
      " [  9 154]] 0.6457023060796646 0.49702380952380953\n",
      "1.0869439154370777 1.4163247408207076 1.3418171335849862\n",
      "Numero de vecinos aplicado: 22\n",
      "[[ 17 156]\n",
      " [ 16 147]] 0.630901287553648 0.4880952380952381\n",
      "1.0869439154370777 1.3640350434217925 1.2578280200758714\n",
      "Numero de vecinos aplicado: 23\n",
      "[[ 12 161]\n",
      " [  9 154]] 0.6443514644351465 0.49404761904761907\n",
      "1.0869439154370777 1.3586714002586437 1.291067018229472\n",
      "Numero de vecinos aplicado: 24\n",
      "[[ 16 157]\n",
      " [ 15 148]] 0.6324786324786325 0.4880952380952381\n",
      "1.0869439154370777 1.2775562878010875 1.188741338903462\n",
      "Numero de vecinos aplicado: 25\n",
      "[[  9 164]\n",
      " [ 11 152]] 0.6346555323590815 0.4791666666666667\n",
      "1.0869439154370777 1.2569183921312959 1.197968216330406\n",
      "Numero de vecinos aplicado: 26\n",
      "[[ 13 160]\n",
      " [ 14 149]] 0.6313559322033899 0.48214285714285715\n",
      "1.0869439154370777 1.1356366629839543 1.0630518557882214\n",
      "Numero de vecinos aplicado: 27\n",
      "[[  7 166]\n",
      " [ 10 153]] 0.6348547717842323 0.47619047619047616\n",
      "1.0869439154370777 0.8467258591305834 0.8118742387046274\n",
      "Numero de vecinos aplicado: 28\n",
      "[[ 10 163]\n",
      " [ 12 151]] 0.6331236897274632 0.4791666666666667\n",
      "1.0869439154370777 0.8801609286352566 0.8363661334733955\n",
      "Numero de vecinos aplicado: 29\n",
      "[[  9 164]\n",
      " [  7 156]] 0.6459627329192547 0.49107142857142855\n",
      "1.0869439154370777 0.9028092699691218 0.8682520334475935\n",
      "Numero de vecinos aplicado: 30\n",
      "[[ 12 161]\n",
      " [  7 156]] 0.65 0.5\n",
      "1.0869439154370777 0.9800570587790898 0.9369004276654586\n"
     ]
    }
   ],
   "source": [
    "for vecinos in range(1,31):\n",
    "    kn = KNeighborsClassifier(n_neighbors=vecinos)\n",
    "    \n",
    "    X_train_c=X_train.copy()\n",
    "    y_train_c=y_train.copy()\n",
    "    X_valid_c=X_valid.copy()\n",
    "    y_valid_c=y_valid.copy()\n",
    "\n",
    "\n",
    "    conf_mat, f1sc, accsc, resultado_naive, resultado_mod, resultado_mod_comis = \\\n",
    "        walk_forward_validation(kn, X_train_c, y_train_c, X_valid_c, y_valid_c, real_valid)\n",
    "    print (\"Numero de vecinos aplicado: \" + str(vecinos))\n",
    "    print(conf_mat, f1sc, accsc)\n",
    "    print(resultado_naive, resultado_mod, resultado_mod_comis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grado aplicado: 30\n",
      "[[  0 173]\n",
      " [  0 163]] 0.6533066132264529 0.4851190476190476\n",
      "1.0869439154370777 1.0869439154370777 1.0869439154370777\n",
      "Grado aplicado: 30\n",
      "[[ 21 152]\n",
      " [ 26 137]] 0.6061946902654868 0.47023809523809523\n",
      "1.0869439154370777 0.7823907151503426 0.7150029609934657\n",
      "Grado aplicado: 30\n",
      "[[  6 167]\n",
      " [ 10 153]] 0.6335403726708075 0.4732142857142857\n",
      "1.0869439154370777 0.8844211861204657 0.8582632593725852\n"
     ]
    }
   ],
   "source": [
    "for grado in range(1,4):\n",
    "    sv = SVC(probability=True, kernel='poly', degree=grado, random_state=0)\n",
    "    \n",
    "    X_train_c=X_train.copy()\n",
    "    y_train_c=y_train.copy()\n",
    "    X_valid_c=X_valid.copy()\n",
    "    y_valid_c=y_valid.copy()\n",
    "\n",
    "\n",
    "    conf_mat, f1sc, accsc, resultado_naive, resultado_mod, resultado_mod_comis = \\\n",
    "        walk_forward_validation(sv, X_train_c, y_train_c, X_valid_c, y_valid_c, real_valid)\n",
    "    print (\"Grado aplicado: \" + str(grado))\n",
    "    print(conf_mat, f1sc, accsc)\n",
    "    print(resultado_naive, resultado_mod, resultado_mod_comis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Profundidad máxima aplicada: 1\n",
      "[[ 15 158]\n",
      " [ 10 153]] 0.6455696202531646 0.5\n",
      "1.0869439154370777 1.125642659116352 1.1088715358581112\n",
      "Profundidad máxima aplicada: 2\n",
      "[[ 23 150]\n",
      " [ 22 141]] 0.6211453744493393 0.4880952380952381\n",
      "1.0869439154370777 1.082021977037323 1.0143855586808417\n",
      "Profundidad máxima aplicada: 3\n",
      "[[ 34 139]\n",
      " [ 29 134]] 0.6146788990825689 0.5\n",
      "1.0869439154370777 1.2384487213368045 1.130082762894619\n",
      "Profundidad máxima aplicada: 4\n",
      "[[ 32 141]\n",
      " [ 30 133]] 0.608695652173913 0.49107142857142855\n",
      "1.0869439154370777 1.040316074018028 0.9351434203946751\n",
      "Profundidad máxima aplicada: 5\n",
      "[[ 34 139]\n",
      " [ 32 131]] 0.605080831408776 0.49107142857142855\n",
      "1.0869439154370777 1.001937288649288 0.8753198322516444\n",
      "Profundidad máxima aplicada: 6\n",
      "[[ 39 134]\n",
      " [ 30 133]] 0.6186046511627907 0.5119047619047619\n",
      "1.0869439154370777 1.0738353313519051 0.9437818928033127\n",
      "Profundidad máxima aplicada: 7\n",
      "[[ 49 124]\n",
      " [ 40 123]] 0.5999999999999999 0.5119047619047619\n",
      "1.0869439154370777 1.1452361882541704 0.9578892478747901\n",
      "Profundidad máxima aplicada: 8\n",
      "[[ 50 123]\n",
      " [ 42 121]] 0.5945945945945946 0.5089285714285714\n",
      "1.0869439154370777 1.0781187836260786 0.893666058026093\n",
      "Profundidad máxima aplicada: 9\n",
      "[[ 58 115]\n",
      " [ 36 127]] 0.6271604938271605 0.5505952380952381\n",
      "1.0869439154370777 1.4711629626285279 1.2397687132620925\n",
      "Profundidad máxima aplicada: 10\n",
      "[[ 58 115]\n",
      " [ 41 122]] 0.6100000000000001 0.5357142857142857\n",
      "1.0869439154370777 1.1171977290084179 0.9136320327429132\n",
      "Profundidad máxima aplicada: 11\n",
      "[[ 66 107]\n",
      " [ 46 117]] 0.6046511627906976 0.5446428571428571\n",
      "1.0869439154370777 1.8851594352281078 1.4983134382533962\n",
      "Profundidad máxima aplicada: 12\n",
      "[[ 62 111]\n",
      " [ 53 110]] 0.5729166666666666 0.5119047619047619\n",
      "1.0869439154370777 0.8503558913931041 0.6768730835424922\n",
      "Profundidad máxima aplicada: 13\n",
      "[[ 71 102]\n",
      " [ 51 112]] 0.5941644562334216 0.5446428571428571\n",
      "1.0869439154370777 1.0731986310186552 0.8516923920973113\n",
      "Profundidad máxima aplicada: 14\n",
      "[[ 76  97]\n",
      " [ 55 108]] 0.5869565217391305 0.5476190476190477\n",
      "1.0869439154370777 1.1175966188005166 0.8724016901592991\n",
      "Profundidad máxima aplicada: 15\n",
      "[[ 73 100]\n",
      " [ 59 104]] 0.5667574931880109 0.5267857142857143\n",
      "1.0869439154370777 0.988234087157374 0.7784000117205859\n",
      "Profundidad máxima aplicada: 16\n",
      "[[ 74  99]\n",
      " [ 62 101]] 0.556473829201102 0.5208333333333334\n",
      "1.0869439154370777 0.763778113926986 0.5980017985805045\n",
      "Profundidad máxima aplicada: 17\n",
      "[[ 77  96]\n",
      " [ 60 103]] 0.5690607734806631 0.5357142857142857\n",
      "1.0869439154370777 1.121339824873298 0.8832430940880256\n",
      "Profundidad máxima aplicada: 18\n",
      "[[ 77  96]\n",
      " [ 58 105]] 0.5769230769230769 0.5416666666666666\n",
      "1.0869439154370777 1.0831198523900294 0.8582765426460218\n",
      "Profundidad máxima aplicada: 19\n",
      "[[ 74  99]\n",
      " [ 57 106]] 0.5760869565217392 0.5357142857142857\n",
      "1.0869439154370777 1.1287202336523694 0.8903919912440352\n",
      "Profundidad máxima aplicada: 20\n",
      "[[80 93]\n",
      " [65 98]] 0.5536723163841808 0.5297619047619048\n",
      "1.0869439154370777 1.0177078093767513 0.793236327898507\n",
      "Profundidad máxima aplicada: 21\n",
      "[[ 77  96]\n",
      " [ 63 100]] 0.5571030640668524 0.5267857142857143\n",
      "1.0869439154370777 0.8931268583303341 0.6950894666697349\n",
      "Profundidad máxima aplicada: 22\n",
      "[[79 94]\n",
      " [68 95]] 0.5397727272727273 0.5178571428571429\n",
      "1.0869439154370777 0.9543664335062286 0.7405235118856188\n",
      "Profundidad máxima aplicada: 23\n",
      "[[ 79  94]\n",
      " [ 63 100]] 0.5602240896358543 0.5327380952380952\n",
      "1.0869439154370777 1.0073568262008337 0.7875292327990528\n",
      "Profundidad máxima aplicada: 24\n",
      "[[ 79  94]\n",
      " [ 62 101]] 0.5642458100558659 0.5357142857142857\n",
      "1.0869439154370777 1.0289806815406026 0.8020227906118076\n",
      "Profundidad máxima aplicada: 25\n",
      "[[79 94]\n",
      " [64 99]] 0.556179775280899 0.5297619047619048\n",
      "1.0869439154370777 0.969775187156229 0.7558760002224948\n",
      "Profundidad máxima aplicada: 26\n",
      "[[79 94]\n",
      " [64 99]] 0.556179775280899 0.5297619047619048\n",
      "1.0869439154370777 0.9800788957782297 0.7662039515686901\n",
      "Profundidad máxima aplicada: 27\n",
      "[[80 93]\n",
      " [64 99]] 0.5577464788732395 0.5327380952380952\n",
      "1.0869439154370777 1.1201955122354668 0.8731187541915595\n",
      "Profundidad máxima aplicada: 28\n",
      "[[80 93]\n",
      " [65 98]] 0.5536723163841808 0.5297619047619048\n",
      "1.0869439154370777 1.1439994206019608 0.8983900778732455\n",
      "Profundidad máxima aplicada: 29\n",
      "[[82 91]\n",
      " [64 99]] 0.5609065155807366 0.5386904761904762\n",
      "1.0869439154370777 1.1641578621056914 0.9060234388238882\n",
      "Profundidad máxima aplicada: 30\n",
      "[[81 92]\n",
      " [65 98]] 0.5552407932011332 0.5327380952380952\n",
      "1.0869439154370777 1.105536559433566 0.860400524643446\n"
     ]
    }
   ],
   "source": [
    "for profund in range(1,31):\n",
    "    dt = DecisionTreeClassifier(max_depth=profund, random_state=0)\n",
    "    \n",
    "    X_train_c=X_train.copy()\n",
    "    y_train_c=y_train.copy()\n",
    "    X_valid_c=X_valid.copy()\n",
    "    y_valid_c=y_valid.copy()\n",
    "\n",
    "\n",
    "    conf_mat, f1sc, accsc, resultado_naive, resultado_mod, resultado_mod_comis = \\\n",
    "        walk_forward_validation(dt, X_train_c, y_train_c, X_valid_c, y_valid_c, real_valid)\n",
    "    print (\"Profundidad máxima aplicada: \" + str(profund))\n",
    "    print(conf_mat, f1sc, accsc)\n",
    "    print(resultado_naive, resultado_mod, resultado_mod_comis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numero de estimadores aplicado: 1\n",
      "[[ 15 158]\n",
      " [ 10 153]] 0.6455696202531646 0.5\n",
      "1.0869439154370777 1.125642659116352 1.1088715358581112\n",
      "Numero de estimadores aplicado: 2\n",
      "[[ 31 142]\n",
      " [ 23 140]] 0.6292134831460674 0.5089285714285714\n",
      "1.0869439154370777 1.0730785593699963 1.0227505745787446\n",
      "Numero de estimadores aplicado: 3\n",
      "[[ 41 132]\n",
      " [ 40 123]] 0.5885167464114833 0.4880952380952381\n",
      "1.0869439154370777 0.8544515137084288 0.7843815473096084\n",
      "Numero de estimadores aplicado: 4\n",
      "[[ 27 146]\n",
      " [ 18 145]] 0.6387665198237885 0.5119047619047619\n",
      "1.0869439154370777 1.4871857181446344 1.4302600414564428\n",
      "Numero de estimadores aplicado: 5\n",
      "[[ 36 137]\n",
      " [ 25 138]] 0.6301369863013698 0.5178571428571429\n",
      "1.0869439154370777 1.540147126928755 1.4417078233160587\n",
      "Numero de estimadores aplicado: 6\n",
      "[[ 40 133]\n",
      " [ 32 131]] 0.613583138173302 0.5089285714285714\n",
      "1.0869439154370777 1.4908836097990215 1.3747998543884816\n",
      "Numero de estimadores aplicado: 7\n",
      "[[ 38 135]\n",
      " [ 36 127]] 0.5976470588235294 0.49107142857142855\n",
      "1.0869439154370777 1.374007703941482 1.2632259636987633\n",
      "Numero de estimadores aplicado: 8\n",
      "[[ 50 123]\n",
      " [ 46 117]] 0.5806451612903225 0.49702380952380953\n",
      "1.0869439154370777 1.375216002505751 1.2195972989291244\n",
      "Numero de estimadores aplicado: 9\n",
      "[[ 49 124]\n",
      " [ 45 118]] 0.5827160493827162 0.49702380952380953\n",
      "1.0869439154370777 1.3416796200368457 1.1970218630090805\n",
      "Numero de estimadores aplicado: 10\n",
      "[[ 49 124]\n",
      " [ 44 119]] 0.5862068965517242 0.5\n",
      "1.0869439154370777 1.3031325219707837 1.1556707463019904\n",
      "Numero de estimadores aplicado: 11\n",
      "[[ 51 122]\n",
      " [ 48 115]] 0.5750000000000001 0.49404761904761907\n",
      "1.0869439154370777 1.19005793604672 1.0490735035622503\n",
      "Numero de estimadores aplicado: 12\n",
      "[[ 52 121]\n",
      " [ 46 117]] 0.5835411471321695 0.5029761904761905\n",
      "1.0869439154370777 1.2240374673530592 1.0725679163602548\n",
      "Numero de estimadores aplicado: 13\n",
      "[[ 49 124]\n",
      " [ 43 120]] 0.5896805896805897 0.5029761904761905\n",
      "1.0869439154370777 1.198653259380421 1.0534829772537895\n",
      "Numero de estimadores aplicado: 14\n",
      "[[ 51 122]\n",
      " [ 43 120]] 0.5925925925925927 0.5089285714285714\n",
      "1.0869439154370777 1.2512353835446337 1.0947556031190269\n",
      "Numero de estimadores aplicado: 15\n",
      "[[ 54 119]\n",
      " [ 43 120]] 0.5970149253731343 0.5178571428571429\n",
      "1.0869439154370777 1.2847286918102023 1.1106421116448777\n",
      "Numero de estimadores aplicado: 16\n",
      "[[ 53 120]\n",
      " [ 43 120]] 0.5955334987593052 0.5148809523809523\n",
      "1.0869439154370777 1.4256431645119176 1.260528040655176\n",
      "Numero de estimadores aplicado: 17\n",
      "[[ 52 121]\n",
      " [ 45 118]] 0.5870646766169154 0.5059523809523809\n",
      "1.0869439154370777 1.3233336358515384 1.1526347756159063\n",
      "Numero de estimadores aplicado: 18\n",
      "[[ 53 120]\n",
      " [ 45 118]] 0.5885286783042394 0.5089285714285714\n",
      "1.0869439154370777 1.31237656919973 1.1499754213819053\n",
      "Numero de estimadores aplicado: 19\n",
      "[[ 56 117]\n",
      " [ 45 118]] 0.592964824120603 0.5178571428571429\n",
      "1.0869439154370777 1.4529994115057623 1.2579983811664504\n",
      "Numero de estimadores aplicado: 20\n",
      "[[ 54 119]\n",
      " [ 49 114]] 0.5757575757575757 0.5\n",
      "1.0869439154370777 1.2588206510603406 1.0801073415797797\n"
     ]
    }
   ],
   "source": [
    "for estimadores in range(1,21):\n",
    "    adab = AdaBoostClassifier(n_estimators=estimadores, random_state=0)\n",
    "    \n",
    "    X_train_c=X_train.copy()\n",
    "    y_train_c=y_train.copy()\n",
    "    X_valid_c=X_valid.copy()\n",
    "    y_valid_c=y_valid.copy()\n",
    "\n",
    "\n",
    "    conf_mat, f1sc, accsc, resultado_naive, resultado_mod, resultado_mod_comis = \\\n",
    "        walk_forward_validation(adab, X_train_c, y_train_c, X_valid_c, y_valid_c, real_valid)\n",
    "    print (\"Numero de estimadores aplicado: \" + str(estimadores))\n",
    "    print(conf_mat, f1sc, accsc)\n",
    "    print(resultado_naive, resultado_mod, resultado_mod_comis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[573, 178],\n",
       "        [122, 803]], dtype=int64),\n",
       " 0.8426023084994754,\n",
       " 0.8210023866348448)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt = DecisionTreeClassifier(max_depth=11)\n",
    "\n",
    "X_train_c=X_train.append(X_valid)\n",
    "y_train_c=y_train.append(y_valid)\n",
    "\n",
    "X_train_c=ct.fit_transform(X_train_c)\n",
    "dt.fit(X_train_c,y_train_c)\n",
    "y_predict=dt.predict(X_train_c)\n",
    "\n",
    "(metrics.confusion_matrix(y_train_c, y_predict), metrics.f1_score(y_train_c,y_predict), metrics.accuracy_score(y_train_c,y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[751,   0],\n",
       "        [  0, 925]], dtype=int64),\n",
       " 1.0,\n",
       " 1.0)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt = DecisionTreeClassifier(max_depth=29)\n",
    "\n",
    "X_train_c=X_train.append(X_valid)\n",
    "y_train_c=y_train.append(y_valid)\n",
    "\n",
    "X_train_c=ct.fit_transform(X_train_c)\n",
    "dt.fit(X_train_c,y_train_c)\n",
    "y_predict=dt.predict(X_train_c)\n",
    "\n",
    "(metrics.confusion_matrix(y_train_c, y_predict), metrics.f1_score(y_train_c,y_predict), metrics.accuracy_score(y_train_c,y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[319, 432],\n",
       "        [184, 741]]),\n",
       " 0.7063870352716872,\n",
       " 0.6324582338902148)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adab = AdaBoostClassifier(n_estimators=19)\n",
    "\n",
    "X_train_c=X_train.append(X_valid)\n",
    "y_train_c=y_train.append(y_valid)\n",
    "\n",
    "X_train_c=ct.fit_transform(X_train_c)\n",
    "adab.fit(X_train_c,y_train_c)\n",
    "y_predict=adab.predict(X_train_c)\n",
    "\n",
    "(metrics.confusion_matrix(y_train_c, y_predict), metrics.f1_score(y_train_c,y_predict), metrics.accuracy_score(y_train_c,y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[475, 276],\n",
       "        [141, 784]]),\n",
       " 0.7899244332493702,\n",
       " 0.7511933174224343)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kn = KNeighborsClassifier(n_neighbors=3)\n",
    "\n",
    "X_train_c=X_train.append(X_valid)\n",
    "y_train_c=y_train.append(y_valid)\n",
    "\n",
    "X_train_c=ct.fit_transform(X_train_c)\n",
    "kn.fit(X_train_c,y_train_c)\n",
    "y_predict=kn.predict(X_train_c)\n",
    "\n",
    "(metrics.confusion_matrix(y_train_c, y_predict), metrics.f1_score(y_train_c,y_predict), metrics.accuracy_score(y_train_c,y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[239, 512],\n",
       "        [134, 791]]),\n",
       " 0.7100538599640933,\n",
       " 0.6145584725536993)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kn = KNeighborsClassifier(n_neighbors=15)\n",
    "\n",
    "X_train_c=X_train.append(X_valid)\n",
    "y_train_c=y_train.append(y_valid)\n",
    "\n",
    "X_train_c=ct.fit_transform(X_train_c)\n",
    "kn.fit(X_train_c,y_train_c)\n",
    "y_predict=kn.predict(X_train_c)\n",
    "\n",
    "(metrics.confusion_matrix(y_train_c, y_predict), metrics.f1_score(y_train_c,y_predict), metrics.accuracy_score(y_train_c,y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 11 177]\n",
      " [  5 226]] 0.7129337539432176 0.5656324582338902\n",
      "3.8420060121748145 5.129345416495867 5.098638520939822\n"
     ]
    }
   ],
   "source": [
    "#Este es el código para ver cómo funciona el modelo de verdad (este es el resultado del basic)\n",
    "\n",
    "dt_final = DecisionTreeClassifier(max_depth=1)\n",
    "\n",
    "X_train_c=X_train.append(X_valid)\n",
    "y_train_c=y_train.append(y_valid)\n",
    "X_test_c=X_test.copy()\n",
    "y_test_c=y_test.copy()\n",
    "\n",
    "conf_mat, f1sc, accsc, resultado_naive, resultado_mod, resultado_mod_comis = \\\n",
    "        walk_forward_validation(dt_final, X_train_c, y_train_c, X_test_c, y_test_c, real_test)\n",
    "print(conf_mat, f1sc, accsc)\n",
    "print(resultado_naive, resultado_mod, resultado_mod_comis)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 15 158]\n",
      " [ 10 153]] 0.6455696202531646 0.5\n",
      "1.086943915437065 1.125642659116341 1.1088715358581016\n"
     ]
    }
   ],
   "source": [
    "X_train_c=X_train.copy()\n",
    "y_train_c=y_train.copy()\n",
    "X_valid_c=X_valid.copy()\n",
    "y_valid_c=y_valid.copy()\n",
    "\n",
    "\n",
    "conf_mat, f1sc, accsc, resultado_naive, resultado_mod, resultado_mod_comis = \\\n",
    "    walk_forward_validation(dt_final, X_train_c, y_train_c, X_valid_c, y_valid_c, real_valid)\n",
    "print(conf_mat, f1sc, accsc)\n",
    "print(resultado_naive, resultado_mod, resultado_mod_comis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
