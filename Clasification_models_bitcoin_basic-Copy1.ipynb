{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from datetime import datetime\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "import numbers\n",
    "from sklearn import model_selection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aquí, a futuro, habría que añadir los datos del Nasdaq, oro y/o Ethereum para ver los resultados\n",
    "data_for_use = pd.read_csv('./bitcoin_data_for_use_v2.csv', index_col=0)\n",
    "data_gold = pd.read_csv('./gold_data_for_use.csv', index_col=0)\n",
    "data_nasdaq = pd.read_csv('./nasdaq_data_for_use.csv', index_col=0)\n",
    "\n",
    "data_for_use_w_gold = data_for_use.merge(data_gold, left_index=True, right_index=True)\n",
    "data_for_use_w_nasdaq = data_for_use.merge(data_nasdaq, left_index=True, right_index=True)\n",
    "\n",
    "data_for_use_w_all = data_for_use_w_gold.merge(data_nasdaq, left_index=True, right_index=True)\n",
    "\n",
    "data_for_use_basic = data_for_use.drop(labels=[\n",
    "                    'varV0','varV1','varV2','varV3','varV4','varV5','varV6','varV7','varV8','varV9',\n",
    "                    'varV10','varV11','varV12','varV13','varV14','varV15','varV16','varV17','varV18','varV19',\n",
    "                    'varV20','varV21','varV22','varV23','varV24','varV25','varV26','varV27','varV28','varV29'\n",
    "                    ], axis=1)\n",
    "\n",
    "data_for_use_bone_deep = data_for_use_basic.drop(labels=['varPm93',\n",
    "                    'varPm123','varPm153','varPm183','varPm213','varPm243','varPm273','varPm303','varPm333',\n",
    "                    'varPs30','varPs37','varPs44','varPs51','varPs58','varPs65','varPs72','varPs79','varPs86'\n",
    "                    ], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>varP0</th>\n",
       "      <th>varP1</th>\n",
       "      <th>varP2</th>\n",
       "      <th>varP3</th>\n",
       "      <th>varP4</th>\n",
       "      <th>varP5</th>\n",
       "      <th>varP6</th>\n",
       "      <th>varP7</th>\n",
       "      <th>varP8</th>\n",
       "      <th>varP9</th>\n",
       "      <th>...</th>\n",
       "      <th>varPm123</th>\n",
       "      <th>varPm153</th>\n",
       "      <th>varPm183</th>\n",
       "      <th>varPm213</th>\n",
       "      <th>varPm243</th>\n",
       "      <th>varPm273</th>\n",
       "      <th>varPm303</th>\n",
       "      <th>varPm333</th>\n",
       "      <th>dia</th>\n",
       "      <th>subida</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2016-01-01</th>\n",
       "      <td>0.008749</td>\n",
       "      <td>0.009252</td>\n",
       "      <td>-0.014696</td>\n",
       "      <td>0.025348</td>\n",
       "      <td>-0.001287</td>\n",
       "      <td>0.013298</td>\n",
       "      <td>-0.084229</td>\n",
       "      <td>0.001468</td>\n",
       "      <td>0.028445</td>\n",
       "      <td>0.013352</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.183043</td>\n",
       "      <td>0.102536</td>\n",
       "      <td>0.131128</td>\n",
       "      <td>-0.060556</td>\n",
       "      <td>-0.054907</td>\n",
       "      <td>-0.068731</td>\n",
       "      <td>0.146342</td>\n",
       "      <td>-0.152457</td>\n",
       "      <td>Friday</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-02</th>\n",
       "      <td>-0.002063</td>\n",
       "      <td>0.008749</td>\n",
       "      <td>0.009252</td>\n",
       "      <td>-0.014696</td>\n",
       "      <td>0.025348</td>\n",
       "      <td>-0.001287</td>\n",
       "      <td>0.013298</td>\n",
       "      <td>-0.084229</td>\n",
       "      <td>0.001468</td>\n",
       "      <td>0.028445</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.192818</td>\n",
       "      <td>0.102514</td>\n",
       "      <td>0.134863</td>\n",
       "      <td>-0.054992</td>\n",
       "      <td>-0.057860</td>\n",
       "      <td>-0.081400</td>\n",
       "      <td>0.215208</td>\n",
       "      <td>-0.139772</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-03</th>\n",
       "      <td>-0.007907</td>\n",
       "      <td>-0.002063</td>\n",
       "      <td>0.008749</td>\n",
       "      <td>0.009252</td>\n",
       "      <td>-0.014696</td>\n",
       "      <td>0.025348</td>\n",
       "      <td>-0.001287</td>\n",
       "      <td>0.013298</td>\n",
       "      <td>-0.084229</td>\n",
       "      <td>0.001468</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.184701</td>\n",
       "      <td>0.077969</td>\n",
       "      <td>0.162987</td>\n",
       "      <td>-0.049962</td>\n",
       "      <td>-0.093926</td>\n",
       "      <td>-0.044459</td>\n",
       "      <td>0.202201</td>\n",
       "      <td>-0.173499</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-04</th>\n",
       "      <td>0.007163</td>\n",
       "      <td>-0.007907</td>\n",
       "      <td>-0.002063</td>\n",
       "      <td>0.008749</td>\n",
       "      <td>0.009252</td>\n",
       "      <td>-0.014696</td>\n",
       "      <td>0.025348</td>\n",
       "      <td>-0.001287</td>\n",
       "      <td>0.013298</td>\n",
       "      <td>-0.084229</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.203476</td>\n",
       "      <td>0.048931</td>\n",
       "      <td>0.208760</td>\n",
       "      <td>-0.021020</td>\n",
       "      <td>-0.100629</td>\n",
       "      <td>-0.075179</td>\n",
       "      <td>0.272441</td>\n",
       "      <td>-0.241372</td>\n",
       "      <td>Monday</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-05</th>\n",
       "      <td>-0.002611</td>\n",
       "      <td>0.007163</td>\n",
       "      <td>-0.007907</td>\n",
       "      <td>-0.002063</td>\n",
       "      <td>0.008749</td>\n",
       "      <td>0.009252</td>\n",
       "      <td>-0.014696</td>\n",
       "      <td>0.025348</td>\n",
       "      <td>-0.001287</td>\n",
       "      <td>0.013298</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.182999</td>\n",
       "      <td>0.047772</td>\n",
       "      <td>0.192408</td>\n",
       "      <td>-0.049361</td>\n",
       "      <td>-0.062588</td>\n",
       "      <td>-0.077178</td>\n",
       "      <td>0.234350</td>\n",
       "      <td>-0.244859</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-09-21</th>\n",
       "      <td>-0.050185</td>\n",
       "      <td>-0.093449</td>\n",
       "      <td>-0.021089</td>\n",
       "      <td>0.021386</td>\n",
       "      <td>-0.010795</td>\n",
       "      <td>-0.008157</td>\n",
       "      <td>0.023015</td>\n",
       "      <td>0.047359</td>\n",
       "      <td>-0.023884</td>\n",
       "      <td>0.019066</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.307969</td>\n",
       "      <td>-0.011426</td>\n",
       "      <td>-0.027993</td>\n",
       "      <td>0.819894</td>\n",
       "      <td>0.296122</td>\n",
       "      <td>0.294667</td>\n",
       "      <td>0.420558</td>\n",
       "      <td>0.264591</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-09-22</th>\n",
       "      <td>0.070793</td>\n",
       "      <td>-0.050185</td>\n",
       "      <td>-0.093449</td>\n",
       "      <td>-0.021089</td>\n",
       "      <td>0.021386</td>\n",
       "      <td>-0.010795</td>\n",
       "      <td>-0.008157</td>\n",
       "      <td>0.023015</td>\n",
       "      <td>0.047359</td>\n",
       "      <td>-0.023884</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.274826</td>\n",
       "      <td>-0.054379</td>\n",
       "      <td>-0.048679</td>\n",
       "      <td>0.743330</td>\n",
       "      <td>0.420131</td>\n",
       "      <td>0.265584</td>\n",
       "      <td>0.400979</td>\n",
       "      <td>0.219860</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-09-23</th>\n",
       "      <td>0.030306</td>\n",
       "      <td>0.070793</td>\n",
       "      <td>-0.050185</td>\n",
       "      <td>-0.093449</td>\n",
       "      <td>-0.021089</td>\n",
       "      <td>0.021386</td>\n",
       "      <td>-0.010795</td>\n",
       "      <td>-0.008157</td>\n",
       "      <td>0.023015</td>\n",
       "      <td>0.047359</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.319474</td>\n",
       "      <td>-0.031845</td>\n",
       "      <td>-0.026437</td>\n",
       "      <td>0.690406</td>\n",
       "      <td>0.351016</td>\n",
       "      <td>0.242234</td>\n",
       "      <td>0.466289</td>\n",
       "      <td>0.217606</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-09-24</th>\n",
       "      <td>-0.045781</td>\n",
       "      <td>0.030306</td>\n",
       "      <td>0.070793</td>\n",
       "      <td>-0.050185</td>\n",
       "      <td>-0.093449</td>\n",
       "      <td>-0.021089</td>\n",
       "      <td>0.021386</td>\n",
       "      <td>-0.010795</td>\n",
       "      <td>-0.008157</td>\n",
       "      <td>0.023015</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.226667</td>\n",
       "      <td>-0.031976</td>\n",
       "      <td>0.058981</td>\n",
       "      <td>0.512089</td>\n",
       "      <td>0.309128</td>\n",
       "      <td>0.316711</td>\n",
       "      <td>0.432640</td>\n",
       "      <td>0.215800</td>\n",
       "      <td>Friday</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-09-25</th>\n",
       "      <td>-0.002875</td>\n",
       "      <td>-0.045781</td>\n",
       "      <td>0.030306</td>\n",
       "      <td>0.070793</td>\n",
       "      <td>-0.050185</td>\n",
       "      <td>-0.093449</td>\n",
       "      <td>-0.021089</td>\n",
       "      <td>0.021386</td>\n",
       "      <td>-0.010795</td>\n",
       "      <td>-0.008157</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.216349</td>\n",
       "      <td>-0.111232</td>\n",
       "      <td>0.109284</td>\n",
       "      <td>0.535708</td>\n",
       "      <td>0.224282</td>\n",
       "      <td>0.541462</td>\n",
       "      <td>0.256068</td>\n",
       "      <td>0.267280</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2095 rows × 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               varP0     varP1     varP2     varP3     varP4     varP5  \\\n",
       "2016-01-01  0.008749  0.009252 -0.014696  0.025348 -0.001287  0.013298   \n",
       "2016-01-02 -0.002063  0.008749  0.009252 -0.014696  0.025348 -0.001287   \n",
       "2016-01-03 -0.007907 -0.002063  0.008749  0.009252 -0.014696  0.025348   \n",
       "2016-01-04  0.007163 -0.007907 -0.002063  0.008749  0.009252 -0.014696   \n",
       "2016-01-05 -0.002611  0.007163 -0.007907 -0.002063  0.008749  0.009252   \n",
       "...              ...       ...       ...       ...       ...       ...   \n",
       "2021-09-21 -0.050185 -0.093449 -0.021089  0.021386 -0.010795 -0.008157   \n",
       "2021-09-22  0.070793 -0.050185 -0.093449 -0.021089  0.021386 -0.010795   \n",
       "2021-09-23  0.030306  0.070793 -0.050185 -0.093449 -0.021089  0.021386   \n",
       "2021-09-24 -0.045781  0.030306  0.070793 -0.050185 -0.093449 -0.021089   \n",
       "2021-09-25 -0.002875 -0.045781  0.030306  0.070793 -0.050185 -0.093449   \n",
       "\n",
       "               varP6     varP7     varP8     varP9  ...  varPm123  varPm153  \\\n",
       "2016-01-01 -0.084229  0.001468  0.028445  0.013352  ... -0.183043  0.102536   \n",
       "2016-01-02  0.013298 -0.084229  0.001468  0.028445  ... -0.192818  0.102514   \n",
       "2016-01-03 -0.001287  0.013298 -0.084229  0.001468  ... -0.184701  0.077969   \n",
       "2016-01-04  0.025348 -0.001287  0.013298 -0.084229  ... -0.203476  0.048931   \n",
       "2016-01-05 -0.014696  0.025348 -0.001287  0.013298  ... -0.182999  0.047772   \n",
       "...              ...       ...       ...       ...  ...       ...       ...   \n",
       "2021-09-21  0.023015  0.047359 -0.023884  0.019066  ... -0.307969 -0.011426   \n",
       "2021-09-22 -0.008157  0.023015  0.047359 -0.023884  ... -0.274826 -0.054379   \n",
       "2021-09-23 -0.010795 -0.008157  0.023015  0.047359  ... -0.319474 -0.031845   \n",
       "2021-09-24  0.021386 -0.010795 -0.008157  0.023015  ... -0.226667 -0.031976   \n",
       "2021-09-25 -0.021089  0.021386 -0.010795 -0.008157  ... -0.216349 -0.111232   \n",
       "\n",
       "            varPm183  varPm213  varPm243  varPm273  varPm303  varPm333  \\\n",
       "2016-01-01  0.131128 -0.060556 -0.054907 -0.068731  0.146342 -0.152457   \n",
       "2016-01-02  0.134863 -0.054992 -0.057860 -0.081400  0.215208 -0.139772   \n",
       "2016-01-03  0.162987 -0.049962 -0.093926 -0.044459  0.202201 -0.173499   \n",
       "2016-01-04  0.208760 -0.021020 -0.100629 -0.075179  0.272441 -0.241372   \n",
       "2016-01-05  0.192408 -0.049361 -0.062588 -0.077178  0.234350 -0.244859   \n",
       "...              ...       ...       ...       ...       ...       ...   \n",
       "2021-09-21 -0.027993  0.819894  0.296122  0.294667  0.420558  0.264591   \n",
       "2021-09-22 -0.048679  0.743330  0.420131  0.265584  0.400979  0.219860   \n",
       "2021-09-23 -0.026437  0.690406  0.351016  0.242234  0.466289  0.217606   \n",
       "2021-09-24  0.058981  0.512089  0.309128  0.316711  0.432640  0.215800   \n",
       "2021-09-25  0.109284  0.535708  0.224282  0.541462  0.256068  0.267280   \n",
       "\n",
       "                  dia  subida  \n",
       "2016-01-01     Friday   False  \n",
       "2016-01-02   Saturday   False  \n",
       "2016-01-03     Sunday    True  \n",
       "2016-01-04     Monday   False  \n",
       "2016-01-05    Tuesday   False  \n",
       "...               ...     ...  \n",
       "2021-09-21    Tuesday    True  \n",
       "2021-09-22  Wednesday    True  \n",
       "2021-09-23   Thursday   False  \n",
       "2021-09-24     Friday   False  \n",
       "2021-09-25   Saturday    True  \n",
       "\n",
       "[2095 rows x 50 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_for_use_basic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#aqui se marca lo que se va a usar de verdad para el resto del programa\n",
    "data_for_use = data_for_use_basic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Partimos los datos en train y test por fechas, sin que sea aleatorio, que es como funcionaría\n",
    "# en la realidad el modelo\n",
    "data_no_test, data_test = train_test_split(data_for_use, shuffle=False, test_size=0.2)\n",
    "\n",
    "# Partimos los datos de train nuevamente en validation y train\n",
    "data_train, data_valid = train_test_split(data_no_test, shuffle=False, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separamos la variable que queremos predecir\n",
    "X_train=data_train.drop(labels=['subida'], axis=1)\n",
    "y_train=data_train['subida']\n",
    "\n",
    "X_valid=data_valid.drop(labels=['subida'], axis=1)\n",
    "y_valid=data_valid['subida']\n",
    "\n",
    "X_test=data_test.drop(labels=['subida'], axis=1)\n",
    "y_test=data_test['subida']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5686567164179105"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Miramos cuántos días sube el bitcoin sobre el total en cada uno de los segmentos\n",
    "# esto nos servirá para hacernos una idea de cómo de buenos son los resultados de los modelos\n",
    "y_train.sum()/y_train.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4851190476190476"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_valid.sum()/y_valid.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5513126491646778"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.sum()/y_test.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tenemos que hacer one-hot encoding sobre la columna \"dia\"\n",
    "#Sobre el resto aplicamos el standardscaler\n",
    "\n",
    "number_columns = data_for_use.select_dtypes('number').columns\n",
    "\n",
    "t=[\n",
    "    ('dia', \n",
    "    OneHotEncoder(handle_unknown='ignore'),\n",
    "    ['dia']),\n",
    "    ('scaler', StandardScaler(),number_columns)\n",
    "    ]\n",
    "\n",
    "ct = ColumnTransformer(transformers=t, remainder='passthrough')\n",
    "\n",
    "#data_for_use_t=ct.fit_transform(data_for_use)\n",
    "\n",
    "#X_train=ct.fit_transform(X_train)\n",
    "#X_valid=ct.transform(X_valid)\n",
    "#X_test=ct.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def walk_forward_validation (model, X_train_wfv, y_train_wfv, X_test_wfv, y_test_wfv):\n",
    "    y_pred_wfv = list()\n",
    "    for i in range(len(y_test_wfv)):\n",
    "        X_train_wfv_ct=ct.fit_transform(X_train_wfv)\n",
    "        model.fit(X_train_wfv_ct, y_train_wfv)\n",
    "        X_test_wfv_ct=ct.transform(X_test_wfv)\n",
    "        y_pred_next = model.predict(X_test_wfv_ct[i:i+1])\n",
    "        y_pred_wfv.append(y_pred_next[0])\n",
    "        X_train_wfv=X_train_wfv.append(X_test_wfv[i:i+1])\n",
    "        y_train_wfv=y_train_wfv.append(pd.Series(y_test_wfv[i]))\n",
    "    \n",
    "    return metrics.confusion_matrix(y_test_wfv, y_pred_wfv), metrics.f1_score(y_test_wfv,y_pred_wfv), metrics.accuracy_score(y_test_wfv,y_pred_wfv)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(penalty='l2', solver='lbfgs')\n",
    "\n",
    "X_train_c=X_train.copy()\n",
    "y_train_c=y_train.copy()\n",
    "X_valid_c=X_valid.copy()\n",
    "y_valid_c=y_valid.copy()\n",
    "\n",
    "\n",
    "conf_mat, f1sc, accsc = walk_forward_validation(lr, X_train_c, y_train_c, X_valid_c, y_valid_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 40 133]\n",
      " [ 32 131]] 0.613583138173302 0.5089285714285714\n"
     ]
    }
   ],
   "source": [
    "print(conf_mat, f1sc, accsc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numero de vecinos aplicado: 1\n",
      "[[ 59 114]\n",
      " [ 61 102]] 0.5382585751978891 0.4791666666666667\n",
      "Numero de vecinos aplicado: 2\n",
      "[[102  71]\n",
      " [ 98  65]] 0.43478260869565216 0.49702380952380953\n",
      "Numero de vecinos aplicado: 3\n",
      "[[ 55 118]\n",
      " [ 53 110]] 0.5626598465473145 0.49107142857142855\n",
      "Numero de vecinos aplicado: 4\n",
      "[[80 93]\n",
      " [76 87]] 0.5072886297376094 0.49702380952380953\n",
      "Numero de vecinos aplicado: 5\n",
      "[[ 46 127]\n",
      " [ 43 120]] 0.5853658536585366 0.49404761904761907\n",
      "Numero de vecinos aplicado: 6\n",
      "[[ 66 107]\n",
      " [ 61 102]] 0.5483870967741935 0.5\n",
      "Numero de vecinos aplicado: 7\n",
      "[[ 33 140]\n",
      " [ 31 132]] 0.6068965517241378 0.49107142857142855\n",
      "Numero de vecinos aplicado: 8\n",
      "[[ 53 120]\n",
      " [ 46 117]] 0.585 0.5059523809523809\n",
      "Numero de vecinos aplicado: 9\n",
      "[[ 30 143]\n",
      " [ 23 140]] 0.6278026905829596 0.5059523809523809\n",
      "Numero de vecinos aplicado: 10\n",
      "[[ 42 131]\n",
      " [ 40 123]] 0.5899280575539568 0.49107142857142855\n",
      "Numero de vecinos aplicado: 11\n",
      "[[ 22 151]\n",
      " [ 19 144]] 0.62882096069869 0.49404761904761907\n",
      "Numero de vecinos aplicado: 12\n",
      "[[ 36 137]\n",
      " [ 33 130]] 0.6046511627906976 0.49404761904761907\n",
      "Numero de vecinos aplicado: 13\n",
      "[[ 20 153]\n",
      " [ 13 150]] 0.6437768240343348 0.5059523809523809\n",
      "Numero de vecinos aplicado: 14\n",
      "[[ 28 145]\n",
      " [ 21 142]] 0.6311111111111111 0.5059523809523809\n",
      "Numero de vecinos aplicado: 15\n",
      "[[ 13 160]\n",
      " [ 15 148]] 0.6284501061571126 0.4791666666666667\n",
      "Numero de vecinos aplicado: 16\n",
      "[[ 23 150]\n",
      " [ 20 143]] 0.6271929824561404 0.49404761904761907\n",
      "Numero de vecinos aplicado: 17\n",
      "[[ 14 159]\n",
      " [ 14 149]] 0.6326963906581741 0.4851190476190476\n",
      "Numero de vecinos aplicado: 18\n",
      "[[ 23 150]\n",
      " [ 19 144]] 0.6301969365426696 0.49702380952380953\n",
      "Numero de vecinos aplicado: 19\n",
      "[[ 11 162]\n",
      " [ 10 153]] 0.6401673640167365 0.4880952380952381\n",
      "Numero de vecinos aplicado: 20\n",
      "[[ 18 155]\n",
      " [ 16 147]] 0.632258064516129 0.49107142857142855\n",
      "Numero de vecinos aplicado: 21\n",
      "[[ 14 159]\n",
      " [  8 155]] 0.649895178197065 0.5029761904761905\n",
      "Numero de vecinos aplicado: 22\n",
      "[[ 14 159]\n",
      " [ 14 149]] 0.6326963906581741 0.4851190476190476\n",
      "Numero de vecinos aplicado: 23\n",
      "[[ 10 163]\n",
      " [ 10 153]] 0.6388308977035491 0.4851190476190476\n",
      "Numero de vecinos aplicado: 24\n",
      "[[ 15 158]\n",
      " [ 17 146]] 0.6252676659528907 0.4791666666666667\n",
      "Numero de vecinos aplicado: 25\n",
      "[[  8 165]\n",
      " [ 13 150]] 0.6276150627615062 0.47023809523809523\n",
      "Numero de vecinos aplicado: 26\n",
      "[[ 12 161]\n",
      " [ 16 147]] 0.624203821656051 0.4732142857142857\n",
      "Numero de vecinos aplicado: 27\n",
      "[[  7 166]\n",
      " [  9 154]] 0.6376811594202898 0.4791666666666667\n",
      "Numero de vecinos aplicado: 28\n",
      "[[ 10 163]\n",
      " [ 13 150]] 0.6302521008403361 0.47619047619047616\n",
      "Numero de vecinos aplicado: 29\n",
      "[[  8 165]\n",
      " [  9 154]] 0.6390041493775934 0.48214285714285715\n",
      "Numero de vecinos aplicado: 30\n",
      "[[ 12 161]\n",
      " [ 11 152]] 0.6386554621848739 0.4880952380952381\n"
     ]
    }
   ],
   "source": [
    "for vecinos in range(1,31):\n",
    "    kn = KNeighborsClassifier(n_neighbors=vecinos)\n",
    "    \n",
    "    X_train_c=X_train.copy()\n",
    "    y_train_c=y_train.copy()\n",
    "    X_valid_c=X_valid.copy()\n",
    "    y_valid_c=y_valid.copy()\n",
    "\n",
    "\n",
    "    conf_mat, f1sc, accsc = walk_forward_validation(kn, X_train_c, y_train_c, X_valid_c, y_valid_c)\n",
    "    print (\"Numero de vecinos aplicado: \" + str(vecinos))\n",
    "    print(conf_mat, f1sc, accsc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maxima profundidad aplicada: 1\n",
      "[[ 15 158]\n",
      " [ 10 153]] 0.6455696202531646 0.5\n",
      "Maxima profundidad aplicada: 2\n",
      "[[ 23 150]\n",
      " [ 22 141]] 0.6211453744493393 0.4880952380952381\n",
      "Maxima profundidad aplicada: 3\n",
      "[[ 33 140]\n",
      " [ 30 133]] 0.6100917431192661 0.49404761904761907\n",
      "Maxima profundidad aplicada: 4\n",
      "[[ 31 142]\n",
      " [ 30 133]] 0.6073059360730593 0.4880952380952381\n",
      "Maxima profundidad aplicada: 5\n",
      "[[ 33 140]\n",
      " [ 35 128]] 0.5939675174013922 0.4791666666666667\n"
     ]
    }
   ],
   "source": [
    "for profund in range(1,31):\n",
    "    dt = DecisionTreeClassifier(max_depth=profund)\n",
    "    \n",
    "    X_train_c=X_train.copy()\n",
    "    y_train_c=y_train.copy()\n",
    "    X_valid_c=X_valid.copy()\n",
    "    y_valid_c=y_valid.copy()\n",
    "\n",
    "\n",
    "    conf_mat, f1sc, accsc = walk_forward_validation(dt, X_train_c, y_train_c, X_valid_c, y_valid_c)\n",
    "    print (\"Maxima profundidad aplicada: \" + str(profund))\n",
    "    print(conf_mat, f1sc, accsc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for estimadores in range(1,21):\n",
    "    adab = AdaBoostClassifier(n_estimators=estimadores)\n",
    "    \n",
    "    X_train_c=X_train.copy()\n",
    "    y_train_c=y_train.copy()\n",
    "    X_valid_c=X_valid.copy()\n",
    "    y_valid_c=y_valid.copy()\n",
    "\n",
    "\n",
    "    conf_mat, f1sc, accsc = walk_forward_validation(adab, X_train_c, y_train_c, X_valid_c, y_valid_c)\n",
    "    print (\"Estimadores aplicados: \" + str(estimadores))\n",
    "    print(conf_mat, f1sc, accsc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = DecisionTreeClassifier(max_depth=9)\n",
    "\n",
    "X_train_c=X_train.append(X_valid)\n",
    "y_train_c=y_train.append(y_valid)\n",
    "\n",
    "X_train_c=ct.fit_transform(X_train_c)\n",
    "dt.fit(X_train_c,y_train_c)\n",
    "y_predict=dt.predict(X_train_c)\n",
    "\n",
    "(metrics.confusion_matrix(y_train_c, y_predict), metrics.f1_score(y_train_c,y_predict), metrics.accuracy_score(y_train_c,y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = DecisionTreeClassifier(max_depth=16)\n",
    "\n",
    "X_train_c=X_train.append(X_valid)\n",
    "y_train_c=y_train.append(y_valid)\n",
    "\n",
    "X_train_c=ct.fit_transform(X_train_c)\n",
    "dt.fit(X_train_c,y_train_c)\n",
    "y_predict=dt.predict(X_train_c)\n",
    "\n",
    "(metrics.confusion_matrix(y_train_c, y_predict), metrics.f1_score(y_train_c,y_predict), metrics.accuracy_score(y_train_c,y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adab = AdaBoostClassifier(n_estimators=19)\n",
    "\n",
    "X_train_c=X_train.append(X_valid)\n",
    "y_train_c=y_train.append(y_valid)\n",
    "\n",
    "X_train_c=ct.fit_transform(X_train_c)\n",
    "adab.fit(X_train_c,y_train_c)\n",
    "y_predict=adab.predict(X_train_c)\n",
    "\n",
    "(metrics.confusion_matrix(y_train_c, y_predict), metrics.f1_score(y_train_c,y_predict), metrics.accuracy_score(y_train_c,y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kn = KNeighborsClassifier(n_neighbors=3)\n",
    "\n",
    "X_train_c=X_train.append(X_valid)\n",
    "y_train_c=y_train.append(y_valid)\n",
    "\n",
    "X_train_c=ct.fit_transform(X_train_c)\n",
    "kn.fit(X_train_c,y_train_c)\n",
    "y_predict=kn.predict(X_train_c)\n",
    "\n",
    "(metrics.confusion_matrix(y_train_c, y_predict), metrics.f1_score(y_train_c,y_predict), metrics.accuracy_score(y_train_c,y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[239, 512],\n",
       "        [134, 791]]),\n",
       " 0.7100538599640933,\n",
       " 0.6145584725536993)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kn = KNeighborsClassifier(n_neighbors=15)\n",
    "\n",
    "X_train_c=X_train.append(X_valid)\n",
    "y_train_c=y_train.append(y_valid)\n",
    "\n",
    "X_train_c=ct.fit_transform(X_train_c)\n",
    "kn.fit(X_train_c,y_train_c)\n",
    "y_predict=kn.predict(X_train_c)\n",
    "\n",
    "(metrics.confusion_matrix(y_train_c, y_predict), metrics.f1_score(y_train_c,y_predict), metrics.accuracy_score(y_train_c,y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 81 107]\n",
      " [ 92 139]] 0.5828092243186582 0.5250596658711217\n"
     ]
    }
   ],
   "source": [
    "#Este es el código para ver cómo funciona el modelo de verdad (este es el resultado del basic)\n",
    "\n",
    "dt = DecisionTreeClassifier(max_depth=14)\n",
    "\n",
    "X_train_c=X_train.append(X_valid)\n",
    "y_train_c=y_train.append(y_valid)\n",
    "X_test_c=X_test.copy()\n",
    "y_test_c=y_test.copy()\n",
    "\n",
    "conf_mat, f1sc, accsc = walk_forward_validation(dt, X_train_c, y_train_c, X_test_c, y_test_c)\n",
    "\n",
    "print(conf_mat, f1sc, accsc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
